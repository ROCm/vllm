vllm bench serve --model <model>  --backend vllm  --host 0.0.0.0 --port 9000  --dataset-name "random"   --random-input-len 1024  --random-output-len 1024 --random-prefix-len 0 --num-prompts 640 --max-concurrency 64 --request-rate "inf" --ignore-eos --save-result --result-dir "/workspace/results/" --result-filename "VLLM_mi355x_gpt-oss-120b_tp8_isl1024_osl1024_c64_s64_mnbt8192.json" --percentile-metrics "ttft,tpot,itl,e2el"
